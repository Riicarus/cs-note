# Cache
## 为什么要用缓存?
> 项目里怎么用的? 为啥用? 没用好会有啥后果?
  
**用缓存的理由:**  
- 高性能: 在内存中, 只有简单的 k-v 对, 性能高.
- 高并发: MySQL 较重, 并发支持不好, 使用缓存简化操作, 提高并发量.
  
**如何使用的:**  
- 结合项目进行阐述, 比如将热点商品放入缓存, 验证码放入缓存等等.

## 缓存问题: 数据一致性
> 主要是缓存和数据库双存储双写, 会导致数据一致性问题.

**严格缓存/数据库一致性:**  
- 读写请求串行化, 都放到同一个内存队列.
- 效率很低
  
**Cache Aside Pattern:**  
- 读操作: 读缓存, 缓存没有就去数据库读, 然后取出数据放入缓存.
- 写操作: 先写数据库, 然后删除缓存.
  - 为什么直接删除缓存: 更新缓存可能涉及很复杂的计算路基, 而且不能保证该缓存会被频繁访问. 用到缓存再去算缓存, 这样开销更少.

### Cache Aside Pattern
**先写数据库, 再删除缓存:**  
- 如果缓存删除失败, 那么数据库中是新数据, 缓存中是旧数据, 数据不一致.
- 先删缓存, 再写数据库. 先删缓存不会导致数据不一致, 只是数据库写失败之后是旧数据(可以重新请求操作).
- 延迟双删: 先写数据库, 再删缓存, delay 一段时间再删除一次缓存.
  
**高并发读写数据, 删除缓存后到数据库找, 但是上一次的数据库写操作还没有执行完, 读取到了旧数据, 更新到缓, 数据库写操作结束后, 缓存和数据库消息不一致.**  
- 写数据库时, 根据数据唯一 id, 将对相同数据的操作路由到同一个同步队列, 对应一个工作线程, 串行执行应操作. 如果数据不在缓存中, 那么把"读取数据 + 更新缓存"的操作以同样的方式放入另一个同步队列.
- 优化: 避免相连的更新缓存请求进入队列, 直接让后续的更新请求自旋等待前面的更新操作完成.
- 排队带来的阻塞问题: 读请求排队可能会使请求阻塞较长时间, 可以引入超时机制, 如果排队超时, 就直接去旧数据. 但是过多读请求排队超时会让请求直接走数据库, 致使缓存击穿.
  - 解决: 加机器, 注意热点商品路由, 避免路由到同一台机器的同一个队列.

## 缓存问题: 缓存雪崩
> 缓存必问问题, 出现之后很致命.  
> 出现情况: 缓存最多抗住 4000 QPS, 高峰请求 5000 QPS, 但是缓存挂了. 5000 请求全部落到数据库, 数据库扛不住, 挂掉, 重启后还是扛不住, 继续挂.

**解决方案:**  
- 事前: Redis 高可用, 主从 + 哨兵, Redis Cluster, 避免全盘崩溃.
- 事中: 本地 EhCache 缓存 + hystrix 限流/降级, 避免 MySQL 扛不住.
- 事后: Redis 持久化, Redis 重启后, 自动从磁盘加载数据, 快速恢复缓存数据.

> 限流: 限制单位时间内能够通过的请求数.  
> 降级: 不真正处理请求, 而是返回一些默认值或者提示.

这样做的优点是 MySQL 一定不会挂掉, 至少能满足一部分用户的请求.

## 缓存问题: 缓存穿透
> 出现情况: 5000 QPS, 但是 4000 QPS 是恶意攻击, 在缓存中查不到(比如 id 为负数).  
> 每次请求都直接走数据库, 不经过缓存, 就像"穿透了缓存"一样.  
> 然后数据库就 G 啦.

**解决方案:**  
- 缓存写空值:  
  - 每次只要从数据没有查到数据, 就向缓存中对应的 key 写一个空值, 然后设置过期时间.
  - 问题: 如果每次攻击使用不同的 id, 写空值就无效了.
- 布隆过滤器:  
  - 在缓存之前添加布隆过滤器, 将数据库所有可能的数据 hash 映射到布隆过滤器中.
  - 对每个请求进行如下判断:
    - 如果请求数据的 key 不在布隆过滤器中, 那么也一定不在数据库中, 直接返回不存在.
    - 如果请求数据的 key 在布隆过滤器中, 就执行正常查询流程.

## 缓存问题: 缓存击穿
> 针对热点 key 的问题, 如果在集中式高并发场景下, **当 key 失效**, 大量请求击穿缓存, 
> 直接请求数据库, 数据库也就 G 啦.

**按照场景确定解决方式:**  
- 如果缓存的数据几乎不会发生更新, 那么直接将热点数据设置为永不过期.
- 如果缓存的数据更新不频繁, 并且刷新缓存耗时少, 可以使用分布式中间件的分布式互斥锁/本地锁来保证只有少量请求可以请求数据库, 并且刷新缓存, 其余线程等待锁释放后可以访问新缓存.
- 如果缓存的数据更新频繁或者刷新缓存耗时长, 可以利用定时线程在缓存过期前主动重新构建缓存或者延长缓存过期时间, 保证所有请求能够访问到对应的缓存.

## 缓存问题: 并发竞争
> 多客户端同时并发写一个 key, 导致数据错误.　　
> 等同于问: Redis 事务的 CAS　方案.

**解决方案:**  
- 基于 Zookeeper 实现分布式锁, 每个系统都通过 Zookeeper 获取分布式锁, 保证同一时间只有一个系统实例在操作某个 key.
- 读入缓存时加入版本号或者时间戳, 比较版本号/时间戳是否比缓存中的更新, 避免用旧的数据覆盖新数据.

## Redis 线程模型
> Redis 线程模型是什么? 为什么 Redis 单线程却能够支持高并发?

Redis 是单线程工作模型. 只使用单核进行处理.  

**为什么是单核的?**  
- Redis 内部使用文件事件处理器(FileEventHandler), 这个文件事件处理器是单线程的.

**为什么支持多个 Socket?**
- 采用 I/O 多路复用机制, 同时监听多个 Socket, 将产生事件的 Socket 压入内存队列, 经由事件分派器进行处理.
- 事件分派器每次从队列中取出一个 Socket 进行处理.

**文件事件处理器结构?**  
- 多个 Socket
- I/O 多路复用程序
- 文件事件分派器
- 事件处理器
  - 连接应答处理器(产生 AE_READABLE 事件)
  - 命令请求处理器(处理 AE_READABLE 事件)
  - 命令回复处理器(处理 AE_WRITABLE)
  
**为什么 Redis 单线程效率也那么高?**
- 纯内存操作
- 非阻塞的 I/O 多路复用机制
- C 语言实现
- 避免多线程上下文切换问题, 预防线程间的竞争

**为什么 Redis 6.0 引入了多线程?**
- 只是在处理网络数据的读写和协议解析时使用多线程
- 执行命令任然是单线程
- 性能瓶颈在网络 I/O 上, 多线程减少对 Redis 主线程的阻塞时间

## Redis 数据结构
> 主要是对各种 Redis 功能的了解.

**数据类型**:  
- String(Simple Dynamic String, SDS)
- Hash
- List
- Set
- Sorted Set

**String:**  
简单 k-v get/set

**Hash:**
- 底层:
  - ziplist:
    - 所有 k-v 字符串长度小于 64 字节
    - k-v 对数量小于 512 个
  - hashtable
  
**List:**
- 有序列表
- 底层:
  - ziplist:
    - 所有 k-v 字符串长度小于 64 字节
    - k-v 对数量小于 512 个
  - linkedlist

**Set:**
- 无须集合, 自动去重
- 底层
  - intset
    - 所有元素都是整数值
    - 元素数量小于 512 个
  - hashtable

**Sorted Set:**
- 有序集合, 自动去重
- 底层:
  - ziplist
    - 元素数量小于 128 个
    - 所有元素长度小于 64 字节
  - skiplist

## Redis 过期策略
> 有哪些过期策略? 有哪些内存淘汰机制? LRU 代码实现?

**过期策略?**
- 定期删除 + 惰性删除
- 定期删除:
  - 每隔一定时间就从 expires 字典中检查一些(随机抽取)设置了过期时间的 key, 如果过期了, 就将其删除.
- 惰性删除:
  - 获取 key 时, 检查 key 是否设置了过期时间并且过期了? 如果过期就删除.
- 大量过期 key 堆积问题:
  - 使用内存淘汰机制.
  
**内存淘汰机制?**  
- noeviction: 当内存不足以容纳新写入数据时, 新写入操作会报错.
- allkeys-lru: 当内存不足以容纳新写入数据时, 在键空间中, 移除最近最少使用的 key(这个是最常用的)
- allkeys-random: 当内存不足以容纳新写入数据时, 在键空间中, 随机移除某个 key.
- volatile-lru: 当内存不足以容纳新写入数据时, 在设置了过期时间的键空间中, 移除最近最少使用的 key.
- volatile-random: 当内存不足以容纳新写入数据时, 在设置了过期时间的键空间中, 随机移除某个 key.
- volatile-ttl: 当内存不足以容纳新写入数据时, 在设置了过期时间的键空间中, 有更早过期时间的 key 优先移除.

**LRU 代码实现?**  
```java
public class LRUCache<K, V> extends LinkedHashMap<K, V> {
  private int capacity;

  public LRUCache(int capacity) {
    super(capacity, 0.75f, true)
    this.capacity = capacity;
  }

  @Override
  protected boolean removeEldestEntry(Map.Entry<K, V> eldest) {
    return size() > capacity;
  }
}
```